{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from growthstandards import rv_to_ds, GrowthStandards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coord_da(vs, name):\n",
    "    return xr.DataArray(vs, dims=name).assign_coords({name: lambda da: da})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_vs = \"weight\", \"len_hei\", \"bmi\", \"wfl\", \"wfh\"\n",
    "\n",
    "fig, axs = plt.subplots(len(_vs), 2, layout=\"constrained\", figsize=(12, 5 * len(_vs)))\n",
    "\n",
    "for raxs, v in zip(axs, _vs):\n",
    "    grv = GrowthStandards[v]\n",
    "    _y = coord_da(np.linspace(grv.ppf(0.01).min(), grv.ppf(0.99).max(), num=1000), v, getattr(grv, \"attrs\", {}))\n",
    "    p2d = grv.pdf(_y, apply_kwargs=dict(keep_attrs=\"drop_conflicts\"))\n",
    "    for ax, s in zip(raxs, (\"Female\", \"Male\")):\n",
    "        p2d.sel(sex=s).drop(\"sex_enum\").plot.imshow(y=v, add_colorbar=False, ax=ax)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: derive P(G_A) from P(W | L), P(W_A), P(L_A), where G = W / L, and A is indexed by age\n",
    "$$\n",
    "\\begin{align}\n",
    "A &= \\text{age} \\\\\n",
    "G &= W / L \\\\\n",
    "p_G(g) &= \\int_L |l| p_{W,L}(g l, l) \\mathrm{d}l \\\\\n",
    "&= \\int_L |l| p_{W | L}(g l | l) p_L(l) \\mathrm{d}l \\\\\n",
    "&= \\mathrm{E}_L[|L| p_{W | L}(g L | L)] \\\\\n",
    "\\mathrm{P}(G=g) &= \\int_L |l| \\mathrm{P}(W = g l | L = l) \\mathrm{P}(L = l) \\mathrm{d}l\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax.numpy as jnp\n",
    "from jax import grad\n",
    "from jax import jit\n",
    "from jax import random\n",
    "from jax import value_and_grad\n",
    "from jax import vmap\n",
    "from jax.random import PRNGKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_probability.substrates import jax as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "tfpk = tfp.math.psd_kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _sex = \"Male\"\n",
    "_len_ds = rv_to_ds(GrowthStandards[\"length\"])  # .sel(sex=_sex)\n",
    "display(_len_ds)\n",
    "_hei_ds = rv_to_ds(GrowthStandards[\"height\"])  # .sel(sex=_sex)\n",
    "display(_hei_ds)\n",
    "_wfl_ds = rv_to_ds(GrowthStandards[\"wfl\"])  # .sel(sex=_sex)\n",
    "display(_wfl_ds)\n",
    "_wfh_ds = rv_to_ds(GrowthStandards[\"wfh\"])  # .sel(sex=_sex)\n",
    "display(_wfh_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import optax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from growthstandards.bcs_ext.tfp_jax_ext import BoxCoxColeGreen, BoxCoxPowerExponential, boxcox, inv_boxcox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bccg_from_ds(ds):\n",
    "    return BoxCoxColeGreen(\n",
    "        ds[\"mu\"].values.astype(np.float32),\n",
    "        ds[\"sigma\"].values.astype(np.float32),\n",
    "        ds[\"nu\"].values.astype(np.float32),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batched over sex, age\n",
    "L = bccg_from_ds(_len_ds)\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.loc, L.quantile(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(L.scale)\n",
    "_L_approx_scale = jnp.arcsinh(\n",
    "    ((L.quantile(0.75) - L.quantile(0.25)) / L.loc) / 2\n",
    ") / stats.norm.ppf(0.75)\n",
    "print(_L_approx_scale)\n",
    "np.allclose(L.scale, _L_approx_scale, rtol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_z = xr.DataArray(\n",
    "    boxcox(L.sample(100, seed=PRNGKey(0)) / L.loc, L.nu) / L.scale,\n",
    "    dims=(\"sample\", \"sex\", \"age\"),\n",
    "    coords={\"sex\": _len_ds[\"sex\"], \"age\": _len_ds[\"age\"]}\n",
    ")\n",
    "_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5), layout=\"constrained\", sharey=True)\n",
    "_z.isel(sex=0).plot.scatter(ax=axs[0], x=\"age\")\n",
    "_z.isel(sex=1).plot.scatter(ax=axs[1], x=\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_wfl_length = _wfl_ds[\"length\"].values.astype(np.float32)\n",
    "# _wfl_mu = _wfl_ds[\"mu\"].values.astype(np.float32)\n",
    "# _wfl_sigma = _wfl_ds[\"sigma\"].values.astype(np.float32)\n",
    "# _wfl_nu = _wfl_ds[\"nu\"].values.astype(np.float32)  # [..., 0]\n",
    "\n",
    "# Batched over sex, length\n",
    "batched_WFL = bccg_from_ds(_wfl_ds)\n",
    "\n",
    "# WFL = tfd.MixtureSameFamily(\n",
    "#     tfd.Categorical(logits=L[..., None].log_prob(_wfl_length)),\n",
    "#     batched_WFL,\n",
    "# )\n",
    "\n",
    "_batched_G = tfd.TransformedDistribution(batched_WFL, tfb.Scale(1 / _wfl_length))\n",
    "batched_G = BoxCoxColeGreen(batched_WFL.loc / _wfl_length, batched_WFL.scale, batched_WFL.nu)\n",
    "assert np.allclose(batched_G.mean(), _batched_G.mean())\n",
    "assert np.allclose(batched_G.variance(), _batched_G.variance())\n",
    "\n",
    "G = tfd.MixtureSameFamily(\n",
    "    tfd.Categorical(logits=L[..., None].log_prob(_wfl_length)),\n",
    "    batched_G[..., None, :],\n",
    ")\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_WFL.loc, batched_WFL.quantile(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_WFL.scale, jnp.arcsinh(\n",
    "    ((batched_WFL.quantile(0.75) - batched_WFL.quantile(0.25)) / batched_WFL.loc) / 2\n",
    "    ) / stats.norm.ppf(0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_sampled_wfl = xr.DataArray(\n",
    "    batched_WFL.sample(100, seed=PRNGKey(0)),\n",
    "    dims=(\"sample\", \"sex\", \"length\"),\n",
    "    coords={\"sex\": _wfl_ds[\"sex\"], \"age\": _wfl_ds[\"length\"]}\n",
    ")\n",
    "_sampled_wfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_sampled_wfl.reduce(stats.skew, dim=\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_z = xr.apply_ufunc(lambda w: boxcox(w / batched_WFL.loc, batched_WFL.nu) / batched_WFL.scale, _sampled_wfl)\n",
    "_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10), layout=\"constrained\", sharey=\"row\")\n",
    "# _sampled_wfl.isel(sex=0).plot.scatter(ax=axs[0, 0], x=\"length\")\n",
    "# _sampled_wfl.isel(sex=1).plot.scatter(ax=axs[0, 1], x=\"length\")\n",
    "\n",
    "_v = (_sampled_wfl / batched_WFL.loc) ** batched_WFL.nu\n",
    "_v.isel(sex=0).plot.scatter(ax=axs[0, 0], x=\"length\")\n",
    "_v.isel(sex=1).plot.scatter(ax=axs[0, 1], x=\"length\")\n",
    "\n",
    "_z.isel(sex=0).plot.scatter(ax=axs[1, 0], x=\"length\")\n",
    "_z.isel(sex=1).plot.scatter(ax=axs[1, 1], x=\"length\")\n",
    "xr.Dataset({\"mean\": _z.mean(dim=\"sample\"), \"std\": _z.std(dim=\"sample\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(batched_WFL.scale * abs(batched_WFL.nu)) / _v.std(dim=\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_v.reduce(stats.skew, dim=\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_probability.python.internal.backend.jax.numpy_math import divide_no_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from growthstandards.bcs_ext.tfp_jax_ext import same_family_mixture_quantile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_median = same_family_mixture_quantile(G, 0.5)\n",
    "g_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_qcv = (3/4) * (same_family_mixture_quantile(G, 0.75) - same_family_mixture_quantile(G, 0.25)) / g_median\n",
    "g_qcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 5), layout=\"constrained\", sharey=True)\n",
    "axs[0].plot(g_qcv[0])\n",
    "axs[1].plot(g_qcv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_approx_sigma = jnp.arcsinh(g_qcv / 1.5) / stats.norm.ppf(0.75)\n",
    "g_approx_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_q0 = 1e-4\n",
    "_lb = same_family_mixture_quantile(G, _q0).min() #.min(axis=-1)\n",
    "_ub = same_family_mixture_quantile(G, 1 - _q0).max() #.max(axis=-1)\n",
    "growth_da = coord_da(np.linspace(_lb, _ub, 1_000), \"growth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_g = xr.apply_ufunc(\n",
    "    G.prob, growth_da, output_core_dims=[[\"sex\", \"age\"]], vectorize=True\n",
    ").assign_coords({\"sex\": _len_ds[\"sex\"], \"age\": _len_ds[\"age\"]})\n",
    "p_g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.components_distribution.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.components_distribution.variance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.components_distribution.scale.sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.components_distribution.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.components_distribution.nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_approx_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_G_part_mix_prob = G.mixture_distribution.probs_parameter()\n",
    "_G_parts = BoxCoxColeGreen(\n",
    "    G.components_distribution.loc * _G_part_mix_prob,\n",
    "    G.components_distribution.scale,\n",
    "    G.components_distribution.nu,\n",
    ")\n",
    "_G_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_median, _G_parts.quantile(0.5).sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.allclose(g_median, _G_parts.quantile(0.5).sum(axis=-1), rtol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_75 = same_family_mixture_quantile(G, 0.75)\n",
    "g_75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_G_parts.quantile(0.75).sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(g_75, _G_parts.quantile(0.75).sum(axis=-1), rtol=5e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(g_75, _G_parts.quantile(0.75).sum(axis=-1), rtol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_qcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _g_qcv = (3/4) * (_G_parts.quantile(0.75) - _G_parts.quantile(0.25)).sum(axis=-1) / _G_parts.loc.sum(axis=-1)\n",
    "_g_qcv = (3/4) * divide_no_nan((_G_parts.quantile(0.75) - _G_parts.quantile(0.25)), _G_parts.loc)\n",
    "_g_qcv.sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_g_qcv = (3/4) * (_G_parts.quantile(0.75).sum(axis=-1) - _G_parts.quantile(0.25).sum(axis=-1)) / _G_parts.loc.sum(axis=-1)\n",
    "_g_qcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_approx_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_G_parts.scale).sum(axis=-1) / 731"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_G_parts.scale * G.mixture_distribution.probs_parameter()).sum(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_G = BoxCoxColeGreen(\n",
    "    _G_parts.loc.sum(axis=-1),\n",
    "    # jnp.sqrt(_G_parts.variance().sum(axis=-1)) / _G_parts.loc.sum(axis=-1),\n",
    "    g_approx_sigma,\n",
    "    # all values equal on last axis\n",
    "    _G_parts.nu[..., 0],\n",
    ")\n",
    "_G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.allclose(same_family_mixture_quantile(G, 0.5), _G.quantile(0.5), rtol=1e-2)\n",
    "np.allclose(g_median, _G.quantile(0.5), rtol=1e-2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(same_family_mixture_quantile(G, 0.75), _G.quantile(0.75), rtol=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(G.mean(), _G.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(G.variance(), _G.variance())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Root = tfd.JointDistributionCoroutine.Root\n",
    "\n",
    "@tfd.JointDistributionCoroutine\n",
    "def test_model():\n",
    "    scale = yield Root(tfd.InverseGaussian(\n",
    "        jnp.mean(g_approx_sigma, axis=-1),\n",
    "        (jnp.mean(g_approx_sigma, axis=-1)**3) / jnp.var(g_approx_sigma, axis=-1),\n",
    "        name=\"sigma\"\n",
    "    )[:, None])\n",
    "    nu = yield (tfd.Normal(\n",
    "        jnp.array([-0.2, -0.2]),\n",
    "        jnp.array([0.1, 0.1]),\n",
    "        name=\"lmbda\"\n",
    "    )[:, None])\n",
    "    g = yield BoxCoxColeGreen(\n",
    "        g_median,\n",
    "        scale,\n",
    "        nu,\n",
    "        name=\"growth\"\n",
    "    )\n",
    "test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = PRNGKey(0)\n",
    "init_seed, seed = jax.random.split(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_fn, build_fn = tfp.experimental.vi.build_affine_surrogate_posterior_from_base_distribution_stateless(\n",
    "    test_model,\n",
    "    operators=\"tril\",\n",
    ")\n",
    "initial_parameters = init_fn(seed=init_seed)\n",
    "initial_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_approx_sigma.mean(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.batch_shape + G.event_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent_G = tfd.Independent(G, 1)\n",
    "\n",
    "init_fn, build_fn = tfp.experimental.util.make_trainable_stateless(\n",
    "    # tfd.Normal,\n",
    "    # tfd.MultivariateNormalDiag,\n",
    "    BoxCoxColeGreen,\n",
    "    # BoxCoxPowerExponential,\n",
    "    # initial_parameters=dict(loc=g_median),\n",
    "    # initial_parameters=dict(scale=g_scale),\n",
    "    initial_parameters=dict(scale=g_approx_sigma),\n",
    "    # initial_parameters=dict(loc=g_median, scale=g_scale),\n",
    "    # initial_parameters=dict(loc=g_median, nu=jnp.ones_like(g_median)),\n",
    "    batch_and_event_shape=(G.batch_shape + G.event_shape),\n",
    "    name=\"q_z\",\n",
    "    # fixed params\n",
    "    loc=g_median,\n",
    "    # scale=g_scale,\n",
    "    # scale=g_approx_sigma,\n",
    "    nu=_G_parts.nu[..., 0],\n",
    ")\n",
    "initial_parameters = init_fn(seed=init_seed)\n",
    "\n",
    "# if \"scale\" in initial_parameters._fields:\n",
    "#     initial_parameters = initial_parameters._replace(\n",
    "#         # scale=initial_parameters.scale[:, :1],\n",
    "#         scale=g_scale.mean(axis=-1)[..., None],\n",
    "#     )\n",
    "\n",
    "if \"nu\" in initial_parameters._fields:\n",
    "    initial_parameters = initial_parameters._replace(\n",
    "        # nu=initial_parameters.nu[:, :1],\n",
    "        nu=jnp.array([-0.17488582, -0.20942171])[..., None],\n",
    "    )\n",
    "if \"power\" in initial_parameters._fields:\n",
    "    initial_parameters = initial_parameters._replace(\n",
    "        # power=initial_parameters.power[:, :1],\n",
    "        power=jnp.array([2.0, 2.0])[..., None],\n",
    "    )\n",
    "\n",
    "\n",
    "# _build_fn = build_fn\n",
    "# def build_fn(*params):\n",
    "#     distr = _build_fn(*params)\n",
    "#     return tfd.Independent(distr, 1)\n",
    "\n",
    "\n",
    "def mixed_log_prob(*params):\n",
    "    print(params, [p.shape for p in params])\n",
    "    distr = build_fn(*params)\n",
    "    print(distr)\n",
    "    *params, growth = params\n",
    "    return G.unnormalized_log_prob(growth)\n",
    "\n",
    "optimized_parameters, result_traces = tfp.vi.fit_surrogate_posterior_stateless(\n",
    "    G.unnormalized_log_prob,\n",
    "    # independent_G.unnormalized_log_prob,\n",
    "    # independent_G.log_prob,\n",
    "    # lambda *params: print(params, [p.shape for p in params]) or G.unnormalized_log_prob(params[-1]),\n",
    "    build_surrogate_posterior_fn=build_fn,\n",
    "    initial_parameters=initial_parameters,\n",
    "    optimizer=optax.adam(learning_rate=0.01),\n",
    "    # num_steps=1_000,\n",
    "    # num_steps=500,\n",
    "    num_steps=400,\n",
    "    # num_steps=100,\n",
    "    # num_steps=10,\n",
    "    # num_steps=1,\n",
    "    sample_size=10,\n",
    "    # sample_size=1,\n",
    "    # jit_compile=True,\n",
    "    # trace_fn=lambda traceable_quantities: traceable_quantities.loss,\n",
    "    trace_fn=lambda traceable_quantities: traceable_quantities,\n",
    "    seed=seed,\n",
    "\n",
    "    # gradient_estimator=tfp.vi.GradientEstimators.SCORE_FUNCTION,\n",
    "    gradient_estimator=tfp.vi.GradientEstimators.DOUBLY_REPARAMETERIZED,\n",
    ")\n",
    "losses = result_traces\n",
    "q_z = build_fn(*optimized_parameters)\n",
    "print(q_z)\n",
    "q_z.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_traces.loss[-1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_traces.loss[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(np.isnan(result_traces.loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_traces._asdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_init_d = build_fn(initial_parameters)\n",
    "display(_init_d.parameters)\n",
    "_init_d.sample([], seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(12, 15), layout=\"constrained\", sharey=\"row\")\n",
    "axs[0, 0].plot(q_z.loc[0])\n",
    "axs[0, 1].plot(q_z.loc[1])\n",
    "axs[1, 0].plot(q_z.scale[0], marker=\".\", ls=\"\")\n",
    "axs[1, 1].plot(q_z.scale[1], marker=\".\", ls=\"\")\n",
    "axs[1, 0].plot(g_approx_sigma[0], 'k--', linewidth=3)\n",
    "axs[1, 1].plot(g_approx_sigma[1], 'k--', linewidth=3)\n",
    "axs[2, 0].plot(100 * abs(q_z.scale[0] - g_approx_sigma[0]) / q_z.scale[0])\n",
    "axs[2, 1].plot(100 * abs(q_z.scale[1] - g_approx_sigma[1]) / q_z.scale[1])\n",
    "print(q_z.nu)\n",
    "if hasattr(q_z, \"power\"):\n",
    "    print(q_z.power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_z.batch_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_g_2 = xr.apply_ufunc(\n",
    "    q_z.prob, growth_da, output_core_dims=[[\"sex\", \"age\"]], vectorize=True\n",
    ").assign_coords({\"sex\": _len_ds[\"sex\"], \"age\": _len_ds[\"age\"]})\n",
    "p_g_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, layout=\"constrained\", figsize=(12, 15))\n",
    "\n",
    "p_g.isel(sex=0).plot(ax=axs[0, 0], x=\"age\")\n",
    "p_g.isel(sex=1).plot(ax=axs[0, 1], x=\"age\")\n",
    "p_g_2.isel(sex=0).plot(ax=axs[1, 0], x=\"age\")\n",
    "p_g_2.isel(sex=1).plot(ax=axs[1, 1], x=\"age\")\n",
    "d_p_g = abs(p_g - p_g_2)\n",
    "# d_p_g = xr.apply_ufunc(divide_no_nan, d_p_g, p_g)\n",
    "d_p_g.isel(sex=0).plot.imshow(ax=axs[2, 0], x=\"age\", vmin=0, vmax=1)\n",
    "d_p_g.isel(sex=1).plot.imshow(ax=axs[2, 1], x=\"age\", vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_p_g.max(), d_p_g.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.batch_shape\n",
    "G.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Root = tfd.JointDistributionCoroutine.Root\n",
    "\n",
    "\n",
    "@tfd.JointDistributionCoroutine\n",
    "def _deterministic_fit_model():\n",
    "    _z = jnp.zeros(G.batch_shape, dtype=G.dtype)\n",
    "    # g = yield Root(G)\n",
    "    mu = yield Root(tfd.Normal(_z, 1.0, name=\"mu\"))\n",
    "    sigma = yield Root(tfd.HalfCauchy(_z, 5.0, name=\"sigma\"))\n",
    "    fit_g = yield tfd.Normal(mu, sigma, name=\"fit_g\")\n",
    "    # yield tfd.Deterministic(g - fit_g, name=\"zero\")\n",
    "    yield tfd.TransformedDistribution(G, tfb.Shift(-fit_g), name=\"zero\")\n",
    "\n",
    "\n",
    "deterministic_fit_model = _deterministic_fit_model.experimental_pin(zero=0.0)\n",
    "deterministic_fit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.components_distribution.quantile(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.mixture_distribution.probs_parameter().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Root = tfd.JointDistributionCoroutine.Root\n",
    "\n",
    "g_median = same_family_mixture_quantile(G, 0.5)\n",
    "\n",
    "\n",
    "@tfd.JointDistributionCoroutine\n",
    "def _fit_model():\n",
    "    _z = jnp.zeros(G.batch_shape, dtype=G.dtype)\n",
    "    # g = yield Root(G)\n",
    "    mu = yield Root(tfd.Normal(g_median, 1.0, name=\"mu\"))\n",
    "    sigma = yield Root(tfd.HalfCauchy(_z, 5.0, name=\"sigma\"))\n",
    "    fit_g = yield tfd.Normal(mu, sigma, name=\"fit_g\")\n",
    "\n",
    "\n",
    "fit_model = _fit_model  # .experimental_pin(zero=0.0)\n",
    "fit_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 0.1\n",
    "num_steps = 500\n",
    "burnin = 50\n",
    "\n",
    "event_space_bijector = fit_model.experimental_default_event_space_bijector()\n",
    "init_state = event_space_bijector.inverse(fit_model.sample(seed=PRNGKey(0)))\n",
    "init_state, treedef = jax.tree_util.tree_flatten(init_state)\n",
    "\n",
    "\n",
    "def target_log_prob_fn(*x):\n",
    "    x = jax.tree_util.tree_unflatten(treedef, x)\n",
    "    y = event_space_bijector.forward(x)\n",
    "    p_y = fit_model.log_prob(y)\n",
    "    p_g = G.log_prob(y.fit_g)\n",
    "    return p_y + p_g\n",
    "\n",
    "\n",
    "def trace_fn(_, pkr):\n",
    "    return (\n",
    "        pkr.inner_results.inner_results.target_log_prob,\n",
    "        pkr.inner_results.inner_results.leapfrogs_taken,\n",
    "        pkr.inner_results.inner_results.has_divergence,\n",
    "        pkr.inner_results.inner_results.energy,\n",
    "        pkr.inner_results.inner_results.log_accept_ratio,\n",
    "    )\n",
    "\n",
    "\n",
    "unconstraining_bijectors = [\n",
    "    tfb.Identity(),\n",
    "    tfb.Identity(),\n",
    "    tfb.Identity(),\n",
    "]\n",
    "\n",
    "kernel = tfp.mcmc.NoUTurnSampler(target_log_prob_fn, step_size=step_size)\n",
    "kernel = tfp.mcmc.TransformedTransitionKernel(\n",
    "    inner_kernel=kernel, bijector=unconstraining_bijectors\n",
    ")\n",
    "\n",
    "hmc = tfp.mcmc.DualAveragingStepSizeAdaptation(\n",
    "    inner_kernel=kernel,\n",
    "    num_adaptation_steps=burnin,\n",
    "    step_size_setter_fn=lambda pkr, new_step_size: pkr._replace(\n",
    "        inner_results=pkr.inner_results._replace(step_size=new_step_size)\n",
    "    ),\n",
    "    step_size_getter_fn=lambda pkr: pkr.inner_results.step_size,\n",
    "    log_accept_prob_getter_fn=lambda pkr: pkr.inner_results.log_accept_ratio,\n",
    ")\n",
    "chain_state, sampler_stat = tfp.mcmc.sample_chain(\n",
    "    num_results=num_steps,\n",
    "    num_burnin_steps=burnin,\n",
    "    current_state=init_state,\n",
    "    kernel=hmc,\n",
    "    trace_fn=trace_fn,\n",
    "    seed=PRNGKey(0),\n",
    ")\n",
    "chain_state, sampler_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfp.mcmc.sample_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_model.sample(seed=PRNGKey(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deterministic_fit_model.sample_and_log_weight([10], seed=PRNGKey(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_G.quantile(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.batch_shape, (\n",
    "    G.mixture_distribution.batch_shape,\n",
    "    G.mixture_distribution._num_categories(),\n",
    "), G.components_distribution.batch_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.sample(seed=PRNGKey(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = xr.DataArray(np.linspace(0.05, 0.2, 1_000), dims=\"growth\").assign_coords(growth=lambda da: da)\n",
    "g = xr.DataArray(np.linspace(0.05, 0.2, 100), dims=\"growth\").assign_coords(\n",
    "    growth=lambda da: da\n",
    ")\n",
    "# p_g = G.prob(np.broadcast_to(g, [*G.batch_shape, len(g)]))\n",
    "p_g = xr.apply_ufunc(G.prob, g, output_core_dims=[[\"sex\", \"age\"]], vectorize=True)\n",
    "p_g = p_g.assign_coords({\"sex\": _len_ds[\"sex\"], \"age\": _len_ds[\"age\"]})\n",
    "p_g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, layout=\"constrained\", figsize=(12, 5))\n",
    "\n",
    "p_g.isel(sex=0).plot(ax=axs[0], x=\"age\")\n",
    "p_g.isel(sex=1).plot(ax=axs[1], x=\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_wfl_length = jnp.array(_wfl_ds[\"length\"].values.astype(np.float32))\n",
    "_wfl_mu = jnp.array(_wfl_ds[\"mu\"].values.astype(np.float32))\n",
    "_wfl_sigma = jnp.array(_wfl_ds[\"sigma\"].values.astype(np.float32))\n",
    "_wfl_nu = jnp.array(_wfl_ds[\"nu\"].values.astype(np.float32))\n",
    "\n",
    "_logits = L[..., None].log_prob(_wfl_length)\n",
    "\n",
    "\n",
    "@tfd.JointDistributionCoroutineAutoBatched\n",
    "def model():\n",
    "    idx = yield tfd.Categorical(logits=_logits, name=\"idx\")\n",
    "    length = _wfl_length[idx]\n",
    "    args = _wfl_mu, _wfl_sigma, _wfl_nu\n",
    "    args = (jnp.take_along_axis(a, idx, axis=-1) for a in args)\n",
    "    weight = yield BoxCoxColeGreen(*args, name=\"wfl\")\n",
    "    # weight = yield tfd.TransformedDistribution(\n",
    "    #     tfd.Normal(0.0, 1.0),\n",
    "    #     tfb.Chain([\n",
    "    #         tfb.Scale(_wfl_mu[idx]),\n",
    "    #         BoxCoxTransform(_wfl_nu[idx]),\n",
    "    #         tfb.Scale(_wfl_sigma[idx])\n",
    "    #     ]),\n",
    "    #     name=\"wfl\",\n",
    "    # )\n",
    "    growth = weight / length\n",
    "\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
